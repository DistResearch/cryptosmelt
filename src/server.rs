use jsonrpc_core::*;
use jsonrpc_core::serde_json::{Map};
use jsonrpc_tcp_server::*;
use std::u32;
use std::net::SocketAddr;
use std::sync::{Arc, Mutex};
use std::result::Result as StdResult;
use concurrent_hashmap::*;
use uuid::*;
use reqwest;
use schedule_recv::periodic_ms;
use std::thread;
use num_bigint::*;
use num_integer::*;
use mithril::byte_string;
use mithril::cryptonight::*;
use cryptonightlite;
use config::*;
use data::InfluxClient;
use regex::Regex;
use longkeccak::keccak;

enum HashType {
  Cryptonight,
  CryptonightLite,
}

fn cn_hash(input: Vec<u8>, hash_type: HashType) -> String {
  let aes = aes::new(aes::AESSupport::HW);
  match hash_type {
    HashType::Cryptonight => hash::hash_alloc_scratchpad(&input, &aes),
    // TODO there are a bunch of warnings generated by unused parts of cryptonightlite.rs
    HashType::CryptonightLite => cryptonightlite::hash_alloc_scratchpad(&input, &aes),
  }
}

#[test]
fn test_hash() {
  let input = byte_string::string_to_u8_array("");
  assert_eq!(cn_hash(input.to_owned(), HashType::Cryptonight), "eb14e8a833fac6fe9a43b57b336789c46ffe93f2868452240720607b14387e11");
  // Test case taken from https://github.com/ExcitableAardvark/node-cryptonight-lite
  assert_eq!(cn_hash(input.to_owned(), HashType::CryptonightLite), "4cec4a947f670ffdd591f89cdb56ba066c31cd093d1d4d7ce15d33704c090611");
  let input2 = byte_string::string_to_u8_array("5468697320697320612074657374");
  assert_eq!(cn_hash(input2, HashType::CryptonightLite), "88e5e684db178c825e4ce3809ccc1cda79cc2adb4406bff93debeaf20a8bebd9");
}



// TODO all of the tree hashing stuff should go in another file
fn tree_hash_cnt(count: usize) -> usize {
  let mut i = 1;
  while i * 2 < count {
    // TODO this isn't optimal, but maybe we don't care
    i *= 2;
  }
  return i;
}

/// From CNS-3 section 3
/// TODO document this, and really everything else, a bit better
fn get_varint(source: &[u8]) -> (usize, usize) {
  if source[0] < 128 {
    return (source[0] as usize, 1);
  }
  let mut i = 0;
  let mut sum: usize = 0;
  while source[i] > 128 {
    let current_b128_digit = (source[i] - 128) as usize;
    // Shifting by i * 7 is multiplying by 128^i, since 128 is our base.
    sum += current_b128_digit << (i * 7);
    i += 1;
  }
  sum += (source[i] as usize) << (i * 7);
  return (sum, i + 1);
}

#[test]
fn test_get_varint() {
  assert_eq!(get_varint(&[42]), (42, 1));
  assert_eq!(get_varint(&[128 + 1, 42]), (42 * 128 + 1, 2));
  assert_eq!(get_varint(&[128 + 60, 128 + 61, 63]), (63 * 128 * 128 + 61 * 128 + 60, 3));
}

fn parse_block_template(template: Vec<u8>) {
  // TODO maybe remove this, since it likely won't be used
  let mut i = 42;
  // The nonce is from bytes 34-38, and the data we need to compute the mining blob starts at 39.
  let (format, format_len) = get_varint(&template[i..]);
  // println!("format {}", format);
  i += format_len;
  let (version, version_len) = get_varint(&template[i..]);
  // println!("version {}", version);
  i += version_len;
  let (unlock_time, unlock_time_len) = get_varint(&template[i..]);
  // println!("unlock_time {}", unlock_time);
  i += unlock_time_len;
  let (input_num, input_num_len) = get_varint(&template[i..]);
  // println!("input_num {}", input_num);
  i += input_num_len;
  i += 1; // input_type which is one byte
  // TODO height is a good checkpoint
  let (height, height_len) = get_varint(&template[i..]);
  i += height_len;
  // println!("Parsed height: {} from {} to {} ", height, i - height_len, i);
  let (output_num, output_num_len) = get_varint(&template[i..]);
  i += output_num_len;
  // println!("Output num: {}", output_num);
  // note: each key in output is 32 bytes, though is preceded by a varint
  for _ in 0..output_num {
    let (_amount, amount_len) = get_varint(&template[i..]);
    // println!("amount {}", _amount);
    i += amount_len;
    // println!("output_type {}", template[i]);
    i += 1; // 1 byte for output_type
    i += 32; // 32 bytes for the key field;
  }
  // println!("extra_size position: {}", i);
  let extra_size = template[i];
  // println!("extra_size {}", extra_size);
  i += 1 + extra_size as usize;
  let (tx_num, tx_num_len) = get_varint(&template[i..]);
  i += tx_num_len;
  // println!("{} bytes remaining, should be 32 * {}", template.len() - i, tx_num);
  // TODO since the daemon returns the extra_nonce offset, we can add 9 (8 for reserve_size and 1
  // for the tx_size field) to get the start of the miner transactions
  // So much of the above might be unnecessary, but we may still need it to find the start of the
  // miner_tx

  // Note:  need to keep in mind, the last byte of the hashing blob is the number of transactions
  // plus 1
}

#[test]
fn test_parse_block_template() {
  let test_block = BlockTemplate {
    blockhashing_blob: "010094fed5d205e42c97122a7b61341c46881837099891d2b2587a0bde019cbae1688e41bc4\
    d70000000005c8e57bea6b5667f77529149756c249904fb346916f7580c18ea64ec793334e903".to_owned(),
    blocktemplate_blob: "010094fed5d205e42c97122a7b61341c46881837099891d2b2587a0bde019cbae1688e41bc\
    4d700000000001e1cf3701ffa5cf3705fbf3b1e40b02d2961caddbcd6294b41030ecf24fadc4229fc45c75df5def56d\
    c1841236db36380f8cce2840202bdba3913153bbbbd8c40a8b9409fe8944bb9964edd905506b558f8eadf027b858080\
    dd9da41702625f0a1c55924dedd94ae36929cfb99664176ff1d6417abfdc5bfb40daf20b9380a094a58d1d027151b66\
    783aa0ed7d3531dcc35b958945491922222327f9bd57693a18b252a6a80c0caf384a302022c8848debdf1f00e5f6a47\
    f0886e5caf027c8fd7e159277f1aa6c5a3796e49ca2b01bdcff031f0dd952991227c05512204eb76400cd8a06c30458\
    31783cd6fbdb9f50208000000000000000002cde625408d94764cf5244bff45ddb0f8d6d42d02b8c6afb99ae9dff33a\
    7bfcacae531ddf666352c45b25569c8d894ed8a327d9fb3c361ed0e7e0433190fe9fec".to_owned(),
    difficulty: 0,
    height: 0,
    prev_hash: "".to_owned(),
    reserved_offset: 285,
    status: "OK".to_owned(),
  };
  assert_eq!(test_block.blockhashing_blob,
             test_block.hashing_blob_with_nonce("0000000000000000").unwrap());
}

fn concat_and_hash(in1: &[u8], in2: &[u8]) -> Vec<u8> {
  let mut concatted_inputs = in1.to_vec();
  concatted_inputs.extend(in2.iter());
  // TODO not sure if &foo[..] is the best way
  // println!("concatted length {}", concatted_inputs.len());
  return keccak(&concatted_inputs[..])[..32].to_vec();
}

// block ends with miner_tx which is a transaction, and tx_hashes which is a list of 32-byte hashes

#[test]
fn test_tree_hash() {
  // Test case pulled from the monero project's tests directory
  let concat_hash_tests = vec![
    byte_string::string_to_u8_array("21f750d5d938dd4ed1fa4daa4d260beb5b73509de9a9b145624d3f1afb671461"),
    byte_string::string_to_u8_array("b07d768cf1f5f8266b89ecdc150a2ad55ccd76d4c12d3a380b21862809a85af6"),
    byte_string::string_to_u8_array("23269a23ee1b4694b26aa317b5cd4f259925f6b3288a8f60fb871b1ad3ac00cb"),
    byte_string::string_to_u8_array("1e6c55eddfc438e1f3e7b638ea6026cc01495010bafdfd789c47dff282c1af4c"),
    byte_string::string_to_u8_array("6a8f83e5f2fca6940a756ef4faa15c7137082a7c31dffe0b2f5112d126ad4af1"),
    byte_string::string_to_u8_array("d536c0e626cc9d2fe1b72256f5285728558f22a3dbb36e0918bcfc01d4ae7284"),
    byte_string::string_to_u8_array("d0bfb8e90647cdb01c292a53a31ff3fe6f350882f1dae2b09374db45f4d54c67"),
    byte_string::string_to_u8_array("d3b4e0829c4f9f63ad235d8ef838d8fb39546d90d99bbd831aff55dbbb642e2b"),
    byte_string::string_to_u8_array("f529ceccd0479b9f194475c2a15143f0edac762e9bbce810436e765550c69e23"),
    byte_string::string_to_u8_array("4c22276c41d7d7e28c10afc5e144a9ce32aa9c0f28bb4fcf171af7d7404fa5e2"),
    byte_string::string_to_u8_array("8b79dc97bd4147f4df6d38b935bd83fb634414bae9d64a32ab45384fba5b8da5"),
    byte_string::string_to_u8_array("c147d51cd2a8f7f2a9c07b1bddc5b28b74bf0c0f0632ac2fc43d0d306dd1ac14"),
    byte_string::string_to_u8_array("81cabe60a358d6043d4733202d489664a929d6bf76a39828954846beb47a3baa"),
    byte_string::string_to_u8_array("cb35d2065cbe3ad34cf78bf895f6323a6d76fc1256306f58e4baecabd7a77938"),
    byte_string::string_to_u8_array("8c6bf2734897c193d39c343fce49a456f0ef84cf963593c5401a14621cc6ec1b"),
    byte_string::string_to_u8_array("ef01b53735ccb02bc96c5fd454105053e3b016174437ed83b25d2a79a88268f2"),
  ];
  let test_tree_hash: Vec<String> = tree_hash(concat_hash_tests).iter()
    .map(|b| format!("{:02x}", b))
    .collect();
  assert_eq!("2d0ad2566627b50cd45125e89e963433b212b368cd2d91662c44813ba9ec90c2",
             test_tree_hash.join(""));
}

// https://lab.getmonero.org/pubs/MRL-0002.pdf
fn tree_hash(hashes: Vec<Vec<u8>>) -> Vec<u8> {
  // TODO get rid of the commented out print statements and leftover C lines
  let count = hashes.len();
  //assert(count > 0);
  if count == 1 {
    return hashes[0].to_vec();
  } else if count == 2 {
    return concat_and_hash(&hashes[0], &hashes[1]);
  } else {
    let mut cnt = tree_hash_cnt(count);
    //let max_size_t = (size_t) - 1; // max allowed value of size_t
    //assert(cnt < max_size_t / 2); // reasonable size to avoid any overflows. /2 is extra; Anyway should be limited much stronger by logical code
    // as we have sane limits on transactions counts in blockchain rules

    // char(*ints)[HASH_SIZE];
    // let ints_size = cnt * HASH_SIZE;
    // ints = alloca(ints_size);
    let mut ints: Vec<Vec<u8>> = Vec::new();
    let slice_point = 2 * cnt - count;
    // memcpy(ints, hashes, (2 * cnt - count) * HASH_SIZE);
    for i in 0..slice_point {
      ints.push(hashes[i].clone())
    }
    // memset(ints, 0, ints_size);  // allocate, and zero out as extra protection for using uninitialized mem
    for i in slice_point..count {
      ints.push(vec![0]);
    }
    /// example, count = 42, then cnt = 32
    /// i,j start off at (2 * 32) - 42, or 22
    /// each iter i = 22 + (2 * (j - 22))
    /// last iter, j = 31
    /// i = 40
    /// so i in [22..40] step 2
    /// j in [22..32] step 1
    /// more generally, i in [(2*cnt - count)..(count)] step 2
    /// and, j in [(2*cnt - count)..(cnt)] step 1
    let mut i = slice_point;
    for j in slice_point..cnt {
      // actually, we want hashes[i] concatted with hashes[i]+1
      // println!("slice point: {}, i: {}, cnt: {}", slice_point, i, cnt);
      // println!("lengths: {}, {}", hashes[i].len(), hashes[i + 1].len());
      ints[j] = concat_and_hash(&hashes[i], &hashes[i + 1]);
      i += 2;
      //cn_fast_hash(hashes[i], 64, ints[j]);
    }
    //assert(i == count);
    // println!("sanity check, {} vs {}", i, count);

    while cnt > 2 {
      cnt /= 2;
      // cnt >>= 1;;
      let mut ii = 0;
      for jj in 0..cnt {
        // println!("slice point: {}, ii: {}, cnt: {}", slice_point, ii, cnt);
        // println!("lengths: {}, {}", ints[ii].len(), ints[ii + 1].len());
        ints[jj] = concat_and_hash(&ints[ii], &ints[ii + 1]);
        ii += 2;
        //cn_fast_hash(ints[i], 64, ints[j]);
      }
    }

    return concat_and_hash(&ints[0], &ints[1]).to_vec();
  }
}

#[derive(Deserialize, Default)]
struct BlockTemplate {
  blockhashing_blob: String,
  blocktemplate_blob: String,
  difficulty: u64,
  height: u64,
  prev_hash: String,
  reserved_offset: u32,
  status: String
}

impl BlockTemplate {
  fn hashing_blob_with_nonce(&self, nonce: &str) -> Option<String> {
    // TODO document this slicing stuff
    let miner_tx = format!(
      "{}{}",
      &self.blocktemplate_blob[86..((self.reserved_offset * 2 - 2) as usize)],
      nonce
    );
    let miner_tx_hash = keccak(&byte_string::string_to_u8_array(&miner_tx))[..32].to_vec();
    let hex_digits_left = (self.blocktemplate_blob.len() - miner_tx.len()) - 86;
    if (hex_digits_left - 2) % 64 != 0 {
      println!("{}", hex_digits_left);
      return None;
    }
    let mut tx_hashes = Vec::new();
    tx_hashes.push(miner_tx_hash);
    for tx_index in 0..(hex_digits_left / 64) {
      // TODO make these numbers less magic, maybe just increment an index for readability
      // TODO the "2" here assumes 1 byte for transaction count, that needs to be a varint as well
      let start = miner_tx.len() + 86 + 2 + 64 * tx_index;
      tx_hashes.push(byte_string::string_to_u8_array(&self.blocktemplate_blob[start..(start + 64)]));
    }
    let num_hashes = tx_hashes.len();
    let root_hash: Vec<String> = tree_hash(tx_hashes).iter()
      .map(|b| format!("{:02x}", b))
      .collect();
    // TODO the count needs to be a varint since we can have more than 255 transactions in a block
    return Some(
      format!("{}{}{:02x}", &self.blockhashing_blob[..86], &root_hash.join(""), num_hashes)
    );
  }
}

// TODO eventually this 'allow' will need to go away
#[allow(dead_code)]
struct Job {
  id: String,
  extra_nonce: String,
  height: u64,
  difficulty: u64,
  diff_hex: String,
  template: Arc<Mutex<BlockTemplate>>,
  submissions: ConcHashMap<String, bool>,
}

impl Job {
  fn submit(&self, nonce: &String) -> Result<Value> {
    if nonce.len() != 8 {
      // We expect a hex representing a 32 bit integer.  We don't care so much about validating that
      // it is purely hexadecimal chaaracters, though, since string_to_u8_array will just zero out
      // anything non-hexadecimal.
      return Err(Error::invalid_params("Nonce must be 8 hexadecimal characters"));
    }
    let previous_submission = self.submissions.insert(nonce.to_owned(), true);
    if let Some(_) = previous_submission {
      // TODO we'll probably want some auto banning functionality in place here
      return Err(Error::invalid_params("Nonce already submitted"));
    }
    // TODO check if the block is expired, may want to do away with the template reference and just
    // check against the current template, since anything of a lower height will be expired as long
    // as we only keep one template per height
    let blob = &self.template.lock().unwrap().blockhashing_blob;
    let (a, _) = blob.split_at(78);
    let (_, b) = blob.split_at(86);
    let hash_input = byte_string::string_to_u8_array(&format!("{}{}{}", a, nonce, b));
    println!("Blob to hash: {}\n {} {} {}", blob, a, nonce, b);
    let hash = cn_hash(hash_input, HashType::CryptonightLite);
    let hash_val = byte_string::hex2_u64_le(&hash[48..]);
    // TODO not entirely sure if the line below is correct
    let achieved_difficulty = u64::max_value() / hash_val;
    println!("Hash value: {}, hash: {}, ratio: {}", hash_val, hash, achieved_difficulty);
    if achieved_difficulty >= self.difficulty {
      println!("Valid job submission");
      return Ok(Value::String("Result accepted".to_owned()));
    }
    else {
      println!("Bad job submission");
    }
    Err(Error::internal_error())
  }
}

// TODO eventually this 'allow' will need to go away
#[allow(dead_code)]
struct Miner {
  miner_id: String,
  login: String,
  password: String,
  peer_addr: SocketAddr,
  difficulty: u64,
  jobs: ConcHashMap<String, Job>,
}

impl Miner {
  /// Returns a representation of the miner's current difficulty, in a hex format which is sort of
  /// a quirk of the stratum protocol.
  fn get_target_hex(&self) -> String {
    let min_diff = BigInt::parse_bytes(
      b"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF", 16).unwrap();
    let full_diff = min_diff.div_floor(&BigInt::from(self.difficulty));
    let (_, full_diff_le) = full_diff.to_bytes_le();
    let full_diff_hexes: Vec<String> = full_diff_le[(full_diff_le.len() - 3)..].iter()
      .map(|b| format!("{:02x}", b))
      .collect();
    full_diff_hexes.join("") + "00"
  }

  fn get_job(&self, current_template: &Arc<Mutex<BlockTemplate>>) -> Result<Value> {
    // Notes on the block template:
    // - reserve_size (8) is the amount of bytes to reserve so the pool can throw in an extra nonce
    // - the daemon returns result.reserved_offset, and that many bytes into
    //   result.blocktemplate_blob, we can write our 8 byte extra nonce
    // - the node pools use a global counter, but we might want the counter to be per-miner
    // - it might not even be necessary to use any counters
    //   (and just go with the first 8 bytes of the miner id)
    let arc_template = current_template.clone();
    let template_data = arc_template.lock().unwrap();
    let job_id = &Uuid::new_v4().to_string();
    // TODO remove the bytes dependency if we don't use it
    //let mut buf = BytesMut::with_capacity(128);
    // TODO at least do something to the reserved bytes
    let target_hex = self.get_target_hex();
    let new_job = Job {
      id: job_id.to_owned(),
      extra_nonce: String::new(),
      height: template_data.height,
      difficulty: self.difficulty,
      diff_hex: target_hex.to_owned(),
      template: current_template.clone(),
      submissions: Default::default(),
    };
    self.jobs.insert(job_id.to_owned(), new_job);
    return Ok(json!({
      "job_id": job_id,
      "blob": template_data.blockhashing_blob,
      "target": target_hex,
    }));
    Err(Error::internal_error())
  }
}

#[derive(Default, Clone)]
struct Meta {
  peer_addr: Option<SocketAddr>
}
impl Metadata for Meta {}

struct PoolServer {
  config: ServerConfig,
  // TODO there will need to be expiry here
  miner_connections: ConcHashMap<String, Miner>,
  block_template: Arc<Mutex<BlockTemplate>>,
  db: Arc<InfluxClient>,
  address_pattern: Regex,
}

impl PoolServer {
  fn new(server_config: &ServerConfig, db: Arc<InfluxClient>)-> PoolServer {
    PoolServer {
      config: server_config.clone(),
      miner_connections: Default::default(),
      block_template: Arc::new(Mutex::new(Default::default())),
      db,
      address_pattern: Regex::new("[a-zA-Z0-9]").unwrap()
    }
  }

  fn getminer(&self, params: &Map<String, Value>) -> Option<&Miner> {
    if let Some(&Value::String(ref id)) = params.get("id") {
      if let Some(miner) = self.miner_connections.find(id) {
        let miner: &Miner = miner.get();
        Some(miner)
      } else {
        None
      }
    } else {
      None
    }
  }

  fn getjob(&self, params: Map<String, Value>) -> Result<Value> {
    if let Some(miner) = self.getminer(&params) {
      miner.get_job(&self.block_template)
    }
    else {
      Err(Error::invalid_params("No miner with this ID"))
    }
  }

  fn login(&self, params: Map<String, Value>, meta: Meta) -> Result<Value> {
    if let None = meta.peer_addr {
      return Err(Error::internal_error());
    }
    if let Some(&Value::String(ref login)) = params.get("login") {
      let id = &Uuid::new_v4().to_string();
      // TODO add some validation on the login address
      let miner = Miner {
        miner_id: id.to_owned(),
        login: login.to_owned(),
        // TODO password isn't used, should probably go away
        password: "".to_owned(),
        peer_addr: meta.peer_addr.unwrap(),
        // TODO implement vardiff
        difficulty: self.config.difficulty,
        jobs: Default::default(),
      };
      let response = json!({
        "id": id,
        "job": miner.get_job(&self.block_template)?,
        "status": "OK",
      });
      self.miner_connections.insert(id.to_owned(), miner);
      Ok(response)
    } else {
      Err(Error::invalid_params("Login address required"))
    }
  }

  fn submit(&self, params: Map<String, Value>) -> Result<Value> {
    if let Some(miner) = self.getminer(&params) {
      if let Some(&Value::String(ref job_id)) = params.get("job_id") {
        if let Some(job) = miner.jobs.find(job_id) {
          if let Some(&Value::String(ref nonce)) = params.get("nonce") {
            println!("nonce: {}", nonce);
            let job = job.get();
            return job.submit(nonce).and_then(|_| {
              if !self.address_pattern.is_match(&miner.login) {
                return Err(Error::invalid_params("Miner ID must be alphanumeric"));
              }
              // TODO maybe insert the nonce and template, that would be cool because then the
              // server becomes fully auditable by connected miners
              let to_insert = format!("valid_share,address={} value={}", miner.login, job.difficulty);
              match self.db.write(&to_insert) {
                Ok(_) => Ok(Value::String("Submission accepted".to_owned())),
                Err(_) => Err(Error::internal_error())
              }
            });
          }
        }
      }
    }
    Err(Error::invalid_params("No miner with this ID"))
  }
}

// TODO this will probably go in another file
fn call_daemon(daemon_url: &str, method: &str, params: Value)
               -> reqwest::Result<Value> {
  let map = json!({
    "jsonrpc": Value::String("2.0".to_owned()),
    "id": Value::String("0".to_owned()),
    "method": Value::String(method.to_owned()),
    "params": params,
  });
  let client = reqwest::Client::new();
  let mut res = client.post(daemon_url)
    .json(&map)
    .send()?;
  res.json()
}

pub fn init(config: Config) {
  let config_ref = Arc::new(config);
  let influx_client = Arc::new(InfluxClient::new(config_ref.clone()));
  let inner_config_ref = config_ref.clone();
  let servers: Vec<Arc<PoolServer>> = config_ref.ports.iter().map(|server_config| {
    let mut io = MetaIoHandler::with_compatibility(Compatibility::Both);
    let pool_server: Arc<PoolServer> = Arc::new(
      PoolServer::new(server_config, influx_client.clone())
    );
    let login_ref = pool_server.clone();
    io.add_method_with_meta("login", move |params, meta: Meta| {
      // TODO repeating this match isn't pretty
      match params {
        Params::Map(map) => login_ref.login(map, meta),
        _ => Err(Error::invalid_params("Expected a params map")),
      }
    });

    let getjob_ref = pool_server.clone();
    io.add_method("getjob", move |params: Params| {
      // TODO repeating this match isn't pretty
      match params {
        Params::Map(map) => getjob_ref.getjob(map),
        _ => Err(Error::invalid_params("Expected a params map")),
      }
    });

    let submit_ref = pool_server.clone();
    io.add_method("submit", move |params| {
      // TODO repeating this match isn't pretty
      match params {
        Params::Map(map) => submit_ref.submit(map),
        _ => Err(Error::invalid_params("Expected a params map")),
      }
    });

    let _keepalived_ref = pool_server.clone();
    io.add_method("keepalived", |_params| {
      Ok(Value::String("hello".to_owned()))
    });

    let server = ServerBuilder::new(io)
      .session_meta_extractor(|context: &RequestContext| {
        Meta {
          peer_addr: Some(context.peer_addr)
        }
      })
      .start(&SocketAddr::new("127.0.0.1".parse().unwrap(), server_config.port))
      .unwrap();
    thread::spawn(|| server.wait());
    pool_server
  }).collect();

  // TODO make sure we refresh the template after every successful submit
  let thread_config_ref = inner_config_ref.clone();
  let tick = periodic_ms(10000);
  loop {
    let params = json!({
        "wallet_address": thread_config_ref.pool_wallet,
        "reserve_size": 8
      });
    let template = call_daemon(&thread_config_ref.daemon_url, "getblocktemplate", params);
    match template {
      Ok(template) => {
        // TODO verify that checking the height (and not prev_hash) is sufficient
        if let Some(result) = template.get("result") {
          for server in servers.iter() {
            let mut current_template = server.block_template.lock().unwrap();
            let parsed_template: StdResult<BlockTemplate, serde_json::Error> =
              serde_json::from_value(result.clone());
            if let Ok(new_template) = parsed_template {
              if new_template.height > current_template.height {
                println!("New block template of height {}.", new_template.height);
                *current_template = new_template;
              }
            }
          }
        }
      },
      Err(message) => println!("Failed to get new block template: {}", message)
    }
    tick.recv().unwrap();
  }
}

#[test]
fn target_hex_correct() {
  let mut miner = Miner {
    miner_id: String::new(),
    login: String::new(),
    password: String::new(),
    peer_addr: "127.0.0.1:3333".parse().unwrap(),
    difficulty: 5000,
    jobs: Default::default(),
  };
  assert_eq!(miner.get_target_hex(), "711b0d00");
  miner.difficulty = 20000;
  assert_eq!(miner.get_target_hex(), "dc460300");
}